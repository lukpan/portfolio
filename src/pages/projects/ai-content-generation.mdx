---
layout: '../../layouts/ProjectLayout.astro'
title: 'AI-powered content generation system'
tagline: 'Scaling instructional design expertise through context-aware AI workflows'
description: 'An intelligent content generation system that embeds instructional design principles directly into AI prompts, enabling consistent, pedagogically sound technical learning content at scale.'
client: 'commercetools'
role: 'Lead Learning Designer & System Architect'
timeline: '6 months (ongoing)'
audience: 'Learning content developers, instructional designers, subject matter experts'
tools: ['GitHub Copilot', 'Claude Sonnet 4.5', 'MDX', 'Moodle XML', 'TypeScript', 'VS Code']
deliverables: ['18+ specialized content generation prompts', '33 instruction files', 'Automated quiz conversion system', '9 learning paths with 40+ modules']
heroImage: '/portfolio/images/ai-content-gen-hero.png'
githubLink: 'https://github.com/commercetools/commercetools-docs'
metrics:
  - label: 'Learning Paths'
    value: '9 active'
  - label: 'Modules Created'
    value: '40+'
  - label: 'Time Saved'
    value: '60-70%'
  - label: 'Format Consistency'
    value: '100%'
---

## The challenge

### Business context

commercetools was scaling rapidly with expanding product capabilities and growing customer base across three continents. The learning team needed to produce high-quality technical content at unprecedented pace to support product launches, customer onboarding, and certification programs. However, manual content creation required 120-150 hours per moduleâ€”creating a bottleneck that limited our ability to serve business needs.

**Strategic objective:** Transform learning content production from a scaling bottleneck into a competitive advantage by leveraging AI to amplify instructional design expertise, enabling the team to double learning path output while maintaining pedagogical quality.

### The scaling problem

Creating high-quality technical learning content requires applying consistent instructional design principles across hundreds of pages while maintaining technical accuracy, pedagogical soundness, and LMS-compatible formatting. Manual content creation couldn't keep pace with commercetools' growing documentation needs.

### Core design challenges

- **Consistency at scale:** Maintain instructional design quality across 9 learning paths and 40+ modules
- **Dual-audience complexity:** Content must serve both web readers and LMS integration (Moodle XML import)
- **Persona alignment:** Every module must speak to "Alex Chen" (mid-to-senior software architects) with appropriate depth and tone
- **Quality assurance:** Ensure AI-generated content meets both technical accuracy and pedagogical standards

### The opportunity

Build an AI system that doesn't just generate contentâ€”but generates *instructional design*. Embed learning theory, writing standards, and assessment principles directly into AI context so expertise scales automatically.

---

## The process

### Research & analysis

**Problem discovery:**
Technical documentation teams struggled with three bottlenecks:

1. **Inconsistent quality:** Different writers applied varying levels of instructional design rigor
2. **Quiz formatting chaos:** Questions existed in 15+ different markdown formats, breaking LMS import
3. **Slow iteration:** Creating a single learning module required 120-150 hours from outline to publication

**User needs identified:**
- Content developers needed guardrails to ensure pedagogical quality without deep ID expertise
- SMEs wanted to contribute content without learning complex formatting rules  
- The LMS team needed standardized quiz formats for automated import

**Core insight:**
If instructional design principles could be codified into AI instructions, the system would apply expertise consistently across all contentâ€”turning every prompt into a teaching moment.

### Design approach

Four key instructional design principles shaped the system architecture:

| Design Principle | Design Rationale |
|-----------------|------------------|
| **Layered context injection.** Instructions load automatically based on file type and pattern matching. | Mirrors how expert IDs shift frameworks based on taskâ€”scaffolding when needed, staying out of the way when not. |
| **Multi-stage cognitive workflow.** Content follows explicit stages: Outline â†’ Research â†’ Draft â†’ Critique â†’ Refine. | Breaking work into discrete stages produces better outcomes than asking AI to "create everything." Each stage optimizes independently. |
| **Persona-driven writing.** All instructions embed "Alex Chen" persona specifications for consistent voice. | Consistent voice requires enforcing *who you're writing for* at the system level, not just style guides. |
| **Dual-format constraints.** Content must work as web pages AND convert cleanly to Moodle XML. | Strict markdown structure enables automated transformation, reducing errors and maintenance burden. |

### Development & iteration

**Key technical implementation decisions:**

**Context routing system**
Used YAML frontmatter with glob patterns (`applyTo: 'websites/learning-*/src/content/**/*.mdx'`) to automatically load relevant instructions when files match patterns. No manual context switching required.

**Prompt library architecture**
Developed 18 specialized prompts organized by workflow stage:
- `learning-1-generate-outline`: Creates persona-aware module structures with learning objectives
- `learning-7-create-scenario-based-quiz-questions`: Generates assessments grounded in "Zen Electron" case study
- `learning-15-standardize-quiz-format`: Transforms inconsistent quizzes into standard markdown
- `learning-16-convert-to-moodle-xml`: Automates LMS-compatible XML generation

**Quality validation integration**
Built critique prompts that evaluate outputs against rubrics covering:
- Semantic clarity (inverted pyramid structure, scannable content)
- Structural consistency (heading hierarchy, list formatting)
- Technical accuracy (API references, code examples)
- Instructional design (learning objectives, knowledge checks, scenario grounding)

### Testing & refinement

**Problem identified:** Early quiz questions were technically correct but pedagogically weakâ€”testing recall instead of applied understanding.

**Solution implemented:**
Rebuilt quiz generation prompt to enforce scenario-based assessment:
- Every question starts with **Scenario:** describing a real situation at "Zen Electron" (fictional company)
- Distractors must be plausible mistakes (not obviously wrong)
- Feedback explains *why* the correct answer solves the scenario

**Quality assurance approach:**
Automated validation catches common errors before human review:
- Heading format compliance (no gerunds, sentence case)
- Terminology consistency (e.g., "commercetools" lowercase)
- Quiz structure validation (numbered questions, required sections)
- Frontmatter completeness

---

## The solution

### What users experience

Content developers work in VS Code with GitHub Copilot. When they create a new learning module file, relevant instructions automatically load based on file path. They invoke prompts through Copilot chat to generate outlines, draft content, create quizzes, and validate formattingâ€”all guided by embedded instructional design expertise.

### System architecture enables

**Intelligent context routing:**
33 instruction files automatically apply based on glob patterns:
```
.github/instructions/
â”œâ”€â”€ learning-quiz-format.instructions.md          # For quiz files
â”œâ”€â”€ learning-markdown-content.instructions.md     # For learning content
â”œâ”€â”€ learning-config-object.instructions.md        # For configuration
â””â”€â”€ [30+ other specialized instruction files]
```

**Multi-stage workflow prompts:**
```
.github/prompts/
â”œâ”€â”€ learning-1-generate-outline.prompt.md
â”œâ”€â”€ learning-2-perform-deep-research.prompt.md
â”œâ”€â”€ learning-3-generate-learning-draft.prompt.md
â”œâ”€â”€ learning-4-critique-draft.prompt.md
â”œâ”€â”€ learning-5-refine-draft.prompt.md
â”œâ”€â”€ learning-7-create-scenario-based-quiz-questions.prompt.md
â”œâ”€â”€ learning-15-standardize-quiz-format.prompt.md
â”œâ”€â”€ learning-16-convert-to-moodle-xml.prompt.md
â””â”€â”€ [10+ additional workflow prompts]
```

**Automated quiz conversion:**
Standardized markdown questions instantly transform to Moodle XML for rapid LMS import:
- One-click conversion eliminates manual XML editing
- Batch processing enables importing entire question banks in seconds
- Proper CDATA wrapping and formatting ensure zero import errors
- Direct upload to Moodle question bank without intermediate steps
- Configurable point allocation (default: 50 points) maintains consistency

### Example workflow

**Creating a new learning module:**

1. Developer creates file: `websites/learning-implement-checkout/src/content/payment-integration.mdx`
2. Instructions for learning content auto-load via pattern match
3. Invoke prompts sequentially through Copilot:
   - Generate outline with learning objectives
   - Perform research using SME documents
   - Generate draft with code examples
   - Critique draft against instructional design rubric
   - Refine based on critique feedback
4. Add scenario-based quiz questions
5. Validate formatting and technical accuracy
6. Publish to documentation site

**Standardizing existing quizzes:**

1. Identify files with inconsistent quiz formats
2. Apply standardization prompt to normalize structure
3. Validate against checklist (numbered questions, scenario format, feedback structure)
4. Convert to Moodle XML for LMS import
5. Import into question bank

---

## Leadership & collaboration

This initiative required driving organizational change and building AI adoption across the learning team:

**Change management & mentorship:**  
Championed AI adoption across the learning organization by demonstrating ROI through working prototypes. Mentored training team in prompt engineering, AI-assisted content creation, and quality validationâ€”increasing team AI literacy from near-zero to confident daily use. Established best practices and guardrails ensuring AI amplifies (rather than replaces) instructional design expertise.

**Executive buy-in:**  
Secured leadership approval for AI investment by building proof-of-concept demonstrating 60% efficiency gains. Presented quarterly updates to senior leadership showing how AI-powered workflows enabled doubling learning path outputâ€”connecting technical innovation to business strategy.

**Knowledge sharing:**  
Created comprehensive documentation enabling team members to leverage the prompt library independently. This democratized AI capabilities across the organization rather than creating single-person dependency.

---

## Results & impact

### Quantified outcomes

- **Scale achieved:** 9 active learning paths containing 40+ individual modules with consistent instructional quality
- **Time efficiency:** 60-70% reduction in initial draft time (from ~12-15 hours to ~4-5 hours per module)
- **Format consistency:** 100% of quiz questions follow standardized format enabling automated LMS import
- **Writing quality:** All content enforces persona-driven writing style across 1000+ pages

### Process improvements

**Before system implementation:**
- 15+ different quiz formatting approaches across documentation
- Manual checking for style guide compliance
- Inconsistent application of instructional design principles
- Quiz import required manual XML editing

**After system implementation:**
- Single standardized quiz format with automated XML conversion
- Automatic validation catches formatting errors pre-review
- Instructional design principles embedded in every prompt
- One-click Moodle import with zero manual editing

### Scalability demonstrated

The system successfully extended to 9 learning paths by following established patterns:
- Create new `websites/learning-{topic}/` folder
- Add config entry in TypeScript configuration
- Register in learning catalogue
- Existing instructions automatically apply via glob patterns

Content types supported:
- Learning modules with embedded assessments
- API documentation with code examples
- Release notes with impact analysis
- Tutorials with step-by-step guidance
- Study guides and certification prep materials

---

## Key takeaways

**Constraints enable creativity.** Strict formatting rules initially felt limiting but ultimately freed cognitive energy for pedagogical quality. When format is standardized, focus shifts to learning design. This principle applies beyond AIâ€”any system benefits from clear constraints.

**Multi-stage workflows produce better outcomes.** Breaking content generation into explicit stages (outline â†’ research â†’ draft â†’ critique â†’ refine) mirrors how expert instructional designers actually work. AI performs significantly better when asked to execute discrete tasks sequentially rather than "create everything."

**Context injection is educational scaffolding.** Just as learners need just-in-time support, AI needs context-specific guidance. The instruction system provides relevant frameworks based on what's being createdâ€”matching scaffolding principles from learning science.

**Automation creates space for higher-order work.** By automating formatting, style consistency, and quiz conversion, instructional designers can focus on curriculum sequencing, assessment design quality, and pedagogical innovation. This reframes the role from "content creator" to "learning experience architect."

**Codifying expertise scales impact.** The system makes instructional design knowledge explicit and reusable. Prompt libraries become organizational learning assetsâ€”capturing best practices that persist beyond individual team members.

---

## Artifacts & documentation

ðŸ“„ [View instruction system](https://github.com/commercetools/commercetools-docs/tree/main/.github/instructions) - 33 context-aware instruction files  
ðŸ“„ [Explore prompt library](https://github.com/commercetools/commercetools-docs/tree/main/.github/prompts) - 18+ specialized workflow prompts  
ðŸ“„ [Sample learning content](https://github.com/commercetools/commercetools-docs/tree/main/websites/learning-implement-checkout/src/content) - Generated modules with quizzes  
ðŸ“„ [System documentation](https://github.com/commercetools/commercetools-docs/blob/main/.github/instructions/README.md) - Architecture overview and usage guide

---

## Future enhancements

**Automated content refresh:** Develop prompts that detect outdated API references and auto-suggest updates when underlying systems change.

**Interactive diagram generation:** Extend prompts to create Mermaid diagrams for architecture concepts with proper accessibility support.

**Learning analytics integration:** Build prompts that analyze low-performing quiz questions in LMS and suggest rewrites to improve clarity.

**Advanced assessment types:** Extend quiz converter to support matching questions, fill-in-blank, and code exercises in Moodle XML format.

**Validation automation:** Create Vale linting rules or custom validators to catch common errors before human reviewâ€”further reducing QA burden.