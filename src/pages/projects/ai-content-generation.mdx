---
layout: '../../layouts/ProjectLayout.astro'
title: 'AI-powered content generation system'
tagline: 'Scaling instructional design expertise through context-aware AI workflows'
description: 'An intelligent content generation system that embeds instructional design principles directly into AI prompts, enabling consistent, pedagogically sound technical learning content at scale.'
client: 'commercetools'
role: 'Learning experience architect'
timeline: '6 months (ongoing)'
audience: 'Learning content developers, instructional designers, subject matter experts'
tools: ['GitHub Copilot', 'Claude Sonnet 4.5', 'MDX', 'Moodle XML', 'TypeScript', 'VS Code']
deliverables: ['18+ specialized content generation prompts', '33 instruction files', 'Automated quiz conversion system', '9 learning paths with 30+ modules']
heroImage: '/portfolio/images/ai-content-gen-hero.png'
metrics:
  - label: 'Learning Paths'
    value: '9'
  - label: 'Modules Created'
    value: '30+'
  - label: 'Time Saved'
    value: '60%'
---

import MermaidDiagram from '../../components/MermaidDiagram.astro';

## The challenge

### Business context

commercetools was scaling rapidly with expanding product capabilities and growing customer base across three continents. The learning team needed to produce high-quality technical content at unprecedented pace to support product launches, customer onboarding, and certification programs. However, manual content creation required 120-150 hours per module‚Äîcreating a bottleneck that limited our ability to serve business needs.

**Strategic objective:** Transform learning content production from a scaling bottleneck into a competitive advantage by leveraging AI to amplify instructional design expertise, enabling the team to double learning path output while maintaining pedagogical quality.

### The scaling problem

Creating high-quality technical learning content requires applying consistent instructional design principles across hundreds of pages while maintaining technical accuracy, pedagogical soundness, and LMS-compatible formatting. Manual content creation couldn't keep pace with commercetools' growing documentation needs.

### Core design challenges

- **Consistency at scale:** Maintain instructional design quality across 9 learning paths and 30+ modules
- **Dual-audience complexity:** Content must serve both web readers and LMS integration (Moodle XML import)
- **Persona alignment:** Every module must speak to "Alex Chen" (mid-to-senior software architects) with appropriate depth and tone
- **Quality assurance:** Ensure AI-generated content meets both technical accuracy and pedagogical standards

### The opportunity

Build an AI system that doesn't just generate content‚Äîbut generates *instructional design*. Embed learning theory, writing standards, and assessment principles directly into AI context so expertise scales automatically.

---

## The process

### Research & analysis

**Problem discovery:**
Technical documentation teams struggled with three bottlenecks:

1. **Inconsistent quality:** Different writers applied varying levels of instructional design rigor
2. **Quiz formatting chaos:** Questions existed in 15+ different markdown formats, breaking LMS import
3. **Slow iteration:** Creating a single learning module required 120-150 hours from outline to publication

**User needs identified:**
- Content developers needed guardrails to ensure pedagogical quality without deep ID expertise
- SMEs wanted to contribute content without learning complex formatting rules  
- The LMS needed standardized quiz formats for automated import

**Core insight:**
If instructional design principles could be codified into AI instructions, the system would apply expertise consistently across all content‚Äîturning every prompt into a teaching moment.

### Design approach

Four key instructional design principles shaped the system architecture:

| Design Principle | Design Rationale |
|-----------------|------------------|
| **Layered context injection.** Instructions load automatically based on file type and pattern matching. | Mirrors how expert IDs shift frameworks based on task‚Äîscaffolding when needed, staying out of the way when not. |
| **Multi-stage cognitive workflow.** Content follows explicit stages: Outline ‚Üí Research ‚Üí Draft ‚Üí Critique ‚Üí Refine. | Breaking work into discrete stages produces better outcomes than asking AI to "create everything." Each stage optimizes independently. |
| **Persona-driven writing.** All instructions embed "Alex Chen" persona specifications for consistent voice. | Consistent voice requires enforcing *who you're writing for* at the system level, not just style guides. |
| **Dual-format constraints.** Content must work as web pages AND convert cleanly to Moodle XML. | Strict markdown structure enables automated transformation, reducing errors and maintenance burden. |

### Development & iteration

**Key technical implementation decisions:**

**Context routing system**
Used YAML frontmatter with glob patterns (`applyTo: 'websites/learning-*/src/content/**/*.mdx'`) to automatically load relevant instructions when files match patterns. No manual context switching required.

**Prompt library architecture**
Developed 18 specialized prompts organized by workflow stage:
- `learning-1-generate-outline`: Creates persona-aware module structures with learning objectives
- `learning-7-create-scenario-based-quiz-questions`: Generates assessments grounded in "Zen Electron" case study
- `learning-15-standardize-quiz-format`: Transforms inconsistent quizzes into standard markdown
- `learning-16-convert-to-moodle-xml`: Automates LMS-compatible XML generation

**Quality validation integration**
Built critique prompts that evaluate outputs against rubrics covering:
- Semantic clarity (inverted pyramid structure, scannable content)
- Structural consistency (heading hierarchy, list formatting)
- Technical accuracy (API references, code examples)
- Instructional design (learning objectives, knowledge checks, scenario grounding)

### Testing & refinement

**Problem identified:** Early quiz questions were technically correct but pedagogically weak‚Äîtesting recall instead of applied understanding.

**Solution implemented:**
Rebuilt quiz generation prompt to enforce scenario-based assessment:
- Every question starts with **Scenario:** describing a real situation at "Zen Electron" (fictional company)
- Distractors must be plausible mistakes (not obviously wrong)
- Feedback explains *why* the correct answer solves the scenario

**Quality assurance approach:**
Automated validation catches common errors before human review:
- Heading format compliance (no gerunds, sentence case)
- Terminology consistency (e.g., "commercetools" lowercase)
- Quiz structure validation (numbered questions, required sections)
- Frontmatter completeness

---

## The solution

### What users experience

Content developers work in VS Code with GitHub Copilot. When they create a new learning module file, relevant instructions automatically load based on file path. They invoke prompts through Copilot chat to generate outlines, draft content, create quizzes, and validate formatting‚Äîall guided by embedded instructional design expertise.

### System architecture

<MermaidDiagram diagram={`graph TD
    subgraph Inputs["üì• INPUTS"]
        SME["üìö SME Knowledge"]
        PERSONA["üë§ Alex Chen Persona"]
        IDP["üìã Instructional Design Plan"]
    end

    subgraph Core["‚öôÔ∏è CORE WORKFLOW"]
        PLAN["üéØ Planning<br/>Generate Outline"]
        RESEARCH["üîç Research<br/>Deep Dive & Examples"]
        DRAFT["‚úçÔ∏è Draft Creation<br/>Content + Code"]
        CRITIQUE["üéì Quality Review<br/>Score Against Rubric"]
        REFINE["‚ú® Refinement<br/>Polish & Improve"]
    end

    subgraph Finalize["üöÄ FINALIZATION"]
        QUIZ["‚ùì Create Quizzes"]
        STYLE["üìê Style & Format"]
        MOODLE["üì¶ Moodle XML"]
        INTEGRATE["üîó Catalogue Integration"]
    end

    subgraph Output["üì§ OUTPUT"]
        FINAL["‚úÖ Published Learning Module"]
    end

    %% Main flow
    Inputs --> PLAN
    PLAN --> RESEARCH
    RESEARCH --> DRAFT
    DRAFT --> CRITIQUE
    CRITIQUE --> REFINE
    REFINE --> QUIZ
    REFINE --> STYLE
    QUIZ --> MOODLE
    STYLE --> INTEGRATE
    MOODLE --> FINAL
    INTEGRATE --> FINAL

    %% Dark theme styling matching Marcus Aurelius
    classDef inputStyle fill:#2d1b0e,stroke:#f59e0b,stroke-width:3px,color:#f9fafb,font-weight:bold;
    classDef coreStyle fill:#1a2234,stroke:#fbbf24,stroke-width:3px,color:#f9fafb,font-weight:bold;
    classDef finalizeStyle fill:#1e1b4b,stroke:#a78bfa,stroke-width:3px,color:#f9fafb,font-weight:bold;
    classDef outputStyle fill:#0f1419,stroke:#fb923c,stroke-width:4px,color:#f9fafb,font-weight:bold;

    class SME,PERSONA,IDP inputStyle
    class PLAN,RESEARCH,DRAFT,CRITIQUE,REFINE coreStyle
    class QUIZ,STYLE,MOODLE,INTEGRATE finalizeStyle
    class FINAL outputStyle
    
    %% Link styling
    linkStyle 0,1,2,3,4 stroke:#fbbf24,stroke-width:3px;
    linkStyle 5,6,7,8 stroke:#a78bfa,stroke-width:3px;
    linkStyle 9,10 stroke:#fb923c,stroke-width:3px;`} />

**Intelligent context routing:**
33 instruction files automatically apply based on glob patterns:

**Automated quiz conversion:**
Standardized markdown questions instantly transform to Moodle XML for rapid LMS import:
- One-click conversion eliminates manual XML editing
- Batch processing enables importing entire question banks in seconds
- Proper CDATA wrapping and formatting ensure zero import errors
- Direct upload to Moodle question bank without intermediate steps
- Configurable point allocation (default: 50 points) maintains consistency

---

## Leadership & collaboration

This initiative required driving organizational change and building AI adoption across the learning team:

**Change management & mentorship:**  
Championed AI adoption across the learning organization by demonstrating ROI through working prototypes. Mentored training team in prompt engineering, AI-assisted content creation, and quality validation‚Äîincreasing team AI literacy. Established best practices and guardrails ensuring AI amplifies (rather than replaces) instructional design expertise.

**Executive buy-in:**  
Secured leadership approval for AI investment by building proof-of-concept demonstrating 60% efficiency gains. Presented quarterly updates to senior leadership showing how AI-powered workflows enabled doubling learning path output‚Äîconnecting technical innovation to business strategy.

**Knowledge sharing:**  
Created comprehensive documentation enabling team members to leverage the prompt library independently. This democratized AI capabilities across the organization rather than creating single-person dependency.

---

## Results & impact

### Quantified outcomes

- **Scale achieved:** 9 active learning paths containing 30+ individual modules with consistent instructional quality
- **Time efficiency:** 60% reduction in initial draft time
- **Format consistency:** 100% of quiz questions follow standardized format enabling automated LMS import
- **Writing quality:** All content enforces persona-driven writing style across 200+ pages

### Process improvements

**Before system implementation:**
- 15+ different quiz formatting approaches across documentation
- Manual checking for style guide compliance
- Inconsistent application of instructional design principles
- Quiz import required manual XML editing

**After system implementation:**
- Single standardized quiz format with automated XML conversion
- Automatic validation catches formatting errors pre-review
- Instructional design principles embedded in every prompt
- One-click Moodle import with zero manual editing

### Scalability demonstrated

**Exponential growth without linear effort:**
The system's true scalability breakthrough lies in how adding new learning paths requires near-zero marginal effort. Creating the first learning path took 6 months to build all the infrastructure. New learning paths now require only 2 hours of setup because all the instructional design logic already exists in reusable prompts and instructions.

**Zero-touch instruction inheritance:**
New learning paths automatically inherit 33 instruction files through glob pattern matching (`websites/learning-*/`). 

This 2 hour setup immediately grants access to 18 specialized prompts covering outline generation, content drafting, quiz creation, and Moodle XML conversion‚Äîcapabilities that took 6 months to develop but now deploy instantly.

**Multi-format content reuse:**
The same instruction foundation supports diverse content types without modification:
- **Learning modules** with scenario-based assessments and knowledge checks
- **API documentation** with embedded code examples and integration patterns
- **Release notes** analyzing feature impact and migration requirements
- **Certification guides** mapping learning objectives to exam domains
- **Tutorials** with progressive complexity and checkpoint validation

**Team multiplication effect:**
By codifying instructional design expertise into reusable prompts, the system transformed how teams scale:
- **Before:** 1 instructional designer could support 2-3 learning paths annually
- **After:** Same designer supports 9 active learning paths with higher consistency
- **Knowledge transfer:** New team members productive in days (not months) by following established prompt workflows

This represents genuine force multiplication‚Äîexpertise captured once, applied infinitely.

---

## Key takeaways

**Constraints enable creativity.** Strict formatting rules initially felt limiting but ultimately freed cognitive energy for pedagogical quality. When format is standardized, focus shifts to learning design. This principle applies beyond AI‚Äîany system benefits from clear constraints.

**Multi-stage workflows produce better outcomes.** Breaking content generation into explicit stages (outline ‚Üí research ‚Üí draft ‚Üí critique ‚Üí refine) mirrors how expert instructional designers actually work. AI performs significantly better when asked to execute discrete tasks sequentially rather than "create everything."

**Context injection is educational scaffolding.** Just as learners need just-in-time support, AI needs context-specific guidance. The instruction system provides relevant frameworks based on what's being created‚Äîmatching scaffolding principles from learning science.

**Automation creates space for higher-order work.** By automating formatting, style consistency, and quiz conversion, instructional designers can focus on curriculum sequencing, assessment design quality, and pedagogical innovation. This reframes the role from "content creator" to "learning experience architect."

**Codifying expertise scales impact.** The system makes instructional design knowledge explicit and reusable. Prompt libraries become organizational learning assets‚Äîcapturing best practices that persist beyond individual team members.

---

## Future enhancements

**Automated content refresh:** Develop prompts that detect outdated API references and auto-suggest updates when underlying systems change.

**Interactive diagram generation:** Extend prompts to create Mermaid diagrams for architecture concepts with proper accessibility support.

**Learning analytics integration:** Build prompts that analyze low-performing quiz questions in LMS and suggest rewrites to improve clarity.

**Advanced assessment types:** Extend quiz converter to support matching questions, fill-in-blank, and code exercises in Moodle XML format.